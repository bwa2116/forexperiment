{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCa-9aQIWRwq"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/bwa2116/forexperiment.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h-WVFdWWWtj"
      },
      "outputs": [],
      "source": [
        "cd /content/forexperiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQa8RgMkjJEJ"
      },
      "outputs": [],
      "source": [
        "from ViT.model import ViTForClassfication\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rs1tmv4VMEL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkfxmz6oVMEM"
      },
      "outputs": [],
      "source": [
        "from ViT.config import data_config\n",
        "from datasets.loader import load_data\n",
        "from trainer import Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCdgGlEnVMEN"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPZpfEZUVMEO"
      },
      "outputs": [],
      "source": [
        "for data in ['MNIST', 'Places365', 'CIFAR10', 'ImageNet200']:\n",
        "    config = data_config[data]\n",
        "\n",
        "    # These are not hard constraints, but are used to prevent misconfigurations\n",
        "    assert config[\"hidden_size\"] % config[\"num_attention_heads\"] == 0\n",
        "    assert config[\"intermediate_size\"] == 4 * config[\"hidden_size\"]\n",
        "    assert config[\"image_size\"] % config[\"patch_size\"] == 0\n",
        "\n",
        "    img_size = (config[\"image_size\"], config[\"image_size\"])\n",
        "    batch_size = 32\n",
        "\n",
        "    trainloader, testloader, _ = load_data(\n",
        "        name=config[\"name\"], img_size=img_size, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    epochs = 20\n",
        "    lr = 1e-4\n",
        "    save_model_every = 0\n",
        "\n",
        "    save_model_every_n_epochs = save_model_every\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for randomfeatures in [False,True]:\n",
        "        if randomfeatures:\n",
        "            attention_type = \"Performer-Softmax\"\n",
        "            m_range = [16, 32, 64, 128]\n",
        "\n",
        "            for m in m_range:\n",
        "                exp_name = (\n",
        "                    data + \"_\" + attention_type + \"_with\" + \"_\" + str(m)\n",
        "                    + \"_\" + \"random features\"\n",
        "                )\n",
        "\n",
        "                print(f\"This is experiment {exp_name}\")\n",
        "\n",
        "                model = ViTForClassfication(\n",
        "                    config,\n",
        "                    randomfeatures=randomfeatures, m=m\n",
        "                )\n",
        "\n",
        "                optimizer = optim.AdamW(model.parameters(),\n",
        "                                        lr=lr, weight_decay=1e-2)\n",
        "\n",
        "                trainer = Trainer(\n",
        "                    model=model,\n",
        "                    config=config,\n",
        "                    optimizer=optimizer,\n",
        "                    loss_fn=loss_fn,\n",
        "                    exp_name=exp_name,\n",
        "                    device=device,\n",
        "                )\n",
        "\n",
        "                trainer.train(\n",
        "                    trainloader,\n",
        "                    testloader,\n",
        "                    epochs,\n",
        "                    save_model_every_n_epochs=save_model_every_n_epochs,\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            m = 1  # dummy variable\n",
        "            for perfrelu in [False, True]:\n",
        "                if perfrelu:\n",
        "                    attention_type = \"Performer-ReLU\"\n",
        "                else:\n",
        "                    attention_type = \"Transformer\"\n",
        "\n",
        "                exp_name = data + \"_\" + attention_type\n",
        "                print(f\"This is experiment {exp_name}\")\n",
        "\n",
        "                model = ViTForClassfication(\n",
        "                    config, perfrelu=perfrelu,\n",
        "                    randomfeatures=randomfeatures, m=m\n",
        "                )\n",
        "\n",
        "                optimizer = optim.AdamW(model.parameters(),\n",
        "                                        lr=lr, weight_decay=1e-2)\n",
        "\n",
        "                trainer = Trainer(\n",
        "                    model=model,\n",
        "                    config=config,\n",
        "                    optimizer=optimizer,\n",
        "                    loss_fn=loss_fn,\n",
        "                    exp_name=exp_name,\n",
        "                    device=device,\n",
        "                )\n",
        "\n",
        "                trainer.train(\n",
        "                    trainloader,\n",
        "                    testloader,\n",
        "                    epochs,\n",
        "                    save_model_every_n_epochs=save_model_every_n_epochs,\n",
        "                )\n",
        "\n",
        "# output:\n",
        "# 1. Transformer\n",
        "# 2. Performer-ReLU\n",
        "# 3. Performer Softmax with random feature 16\n",
        "# 4. Performer Softmax with random feature 32\n",
        "# 5. Performer Softmax with random feature 64\n",
        "# 6. Performer Softmax with random feature 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "%cd /content/forexperiment"
      ],
      "metadata": {
        "id": "Kw2nb86xjuPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r experiments.zip experiments/\n",
        "files.download('experiments.zip')"
      ],
      "metadata": {
        "id": "E04lKC5NloD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehl9lyjQpnCZ"
      },
      "source": [
        "# Inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcoMH0ogofMR"
      },
      "outputs": [],
      "source": [
        "from ViT.utils import visualize_images, visualize_attention, load_experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NMhQO2289ce"
      },
      "outputs": [],
      "source": [
        "visualize_images('MNIST') # Show some training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zf2BqmjpudT"
      },
      "outputs": [],
      "source": [
        "# Load Experiment\n",
        "config, model, train_losses, test_losses, accuracies = load_experiment(\"MNIST_Performer-ReLU\")\n",
        "\n",
        "# Create two subplots of train/test losses and accuracies\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax1.plot(train_losses, label=\"Train loss\")\n",
        "ax1.plot(test_losses, label=\"Test loss\")\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "ax1.legend()\n",
        "ax2.plot(accuracies)\n",
        "ax2.set_xlabel(\"Epoch\")\n",
        "ax2.set_ylabel(\"Accuracy\")\n",
        "plt.savefig(\"metrics.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loX3SzJdp3N0"
      },
      "outputs": [],
      "source": [
        "visualize_attention(model,'MNIST', \"attention.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}